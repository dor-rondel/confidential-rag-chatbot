version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - '11435:11434'
    volumes:
      - ./ollama_data:/root/.ollama
    container_name: ollama
    healthcheck:
      test: ["CMD-SHELL", "ollama list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # One-off init container to ensure the embedding model is pulled.
  # Waits for the ollama API by polling `ollama list` (no curl dependency).
  ollama-model-pull:
    image: ollama/ollama:latest
    depends_on:
      - ollama
    volumes:
      - ./ollama_data:/root/.ollama
    entrypoint: ["/bin/sh", "-c"]
    command: ["until ollama list >/dev/null 2>&1; do echo 'Waiting for ollama...'; sleep 2; done; echo 'Ollama is up'; ollama pull nomic-embed-text || echo 'Model already present' "]
    restart: "no"

  chroma:
    image: chromadb/chroma:latest
    ports:
      - '8000:8000'
    volumes:
      - ./chroma_data:/chroma/.chroma/index
    container_name: chroma
